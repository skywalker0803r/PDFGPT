import os
import streamlit as st
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
import tempfile

# 1. Streamlit ä»‹é¢
st.title("ğŸ“š GPT PDF å•ç­”æ©Ÿ (è¼¸å…¥é‡‘é‘°ç‰ˆ)")
st.write("ä¸Šå‚³ PDFï¼Œè¼¸å…¥ OpenAI é‡‘é‘°ï¼Œé–‹å§‹å•å•é¡Œï¼")

# 2. è¦æ±‚ä½¿ç”¨è€…è¼¸å…¥ OpenAI API Key
openai_api_key = st.text_input("è«‹è¼¸å…¥ä½ çš„ OpenAI API é‡‘é‘°ï¼š", type="password")

# 3. ä¸Šå‚³ PDF
uploaded_file = st.file_uploader("é¸æ“‡ä¸€ä»½ PDF æª”æ¡ˆ", type="pdf")

if openai_api_key and uploaded_file is not None:
    # è¨­å®šç’°å¢ƒè®Šæ•¸ (è‡¨æ™‚)
    os.environ["OPENAI_API_KEY"] = openai_api_key

    # æŠŠä¸Šå‚³çš„æª”æ¡ˆå­˜åˆ°è‡¨æ™‚æª”æ¡ˆ
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_file_path = tmp_file.name

    # è®€å– PDF
    loader = PyPDFLoader(tmp_file_path)
    documents = loader.load()

    # åˆ‡å‰²æˆå°æ®µè½
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = text_splitter.split_documents(documents)

    # å»ºç«‹å‘é‡è³‡æ–™åº«
    embeddings = OpenAIEmbeddings()
    db = FAISS.from_documents(docs, embeddings)

    # åˆå§‹åŒ– LLM
    llm = ChatOpenAI(model="gpt-4o")  # æˆ– gpt-3.5-turbo
    qa = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=db.as_retriever()
    )

    # å•å•é¡Œ
    query = st.text_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œï¼š")

    if st.button("é€å‡ºå•é¡Œ"):
        if query:
            with st.spinner("æ€è€ƒä¸­..."):
                result = qa.invoke(query)
                st.success(result["result"])
        else:
            st.warning("è«‹å…ˆè¼¸å…¥ä¸€å€‹å•é¡Œï¼")
else:
    st.info("è«‹å…ˆè¼¸å…¥ OpenAI API é‡‘é‘°ï¼Œä¸¦ä¸Šå‚³ PDF æª”æ¡ˆã€‚")
